# LMM_models

Checkout [this article](https://huyenchip.com/2023/10/10/multimodal.html) that highlights the most interesting elements to understand about multimodal models : 
- CLIP Joint-embedding model, to generate embeddings of text and image in the same space using contrastive learning
- Large multimodal models like Flamingo, that uses image encoder part of clip like models plus a LLM part to generate texts

Checkout [LLaVa](https://llava-vl.github.io/) to get an idea about instruction tuning of LMM 

